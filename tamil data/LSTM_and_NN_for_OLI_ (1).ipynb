{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM and NN for OLI .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdbxAM5VEc8-"
      },
      "source": [
        "**Importing Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QTmKTgSeeuQ"
      },
      "source": [
        "#importing required libaries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re \n",
        "import string\n",
        "\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "\n",
        "#keras\n",
        "from keras import *\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.optimizers import  Adam\n",
        "from keras import regularizers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkpCVt-IEhxb"
      },
      "source": [
        "**Tamil Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg7J-VrzfTBD"
      },
      "source": [
        "#reading the Tamil dataset\n",
        "train=pd.read_csv('/content/drive/MyDrive/offensive language/Tamil dataset/Tamil-Codemixed_offensive_Training-Tweet.tsv',sep='\\t', index_col=[0])\n",
        "test=pd.read_csv('/content/drive/MyDrive/offensive language/Tamil dataset/Tamil_hasoc_tanglish_test_withlabels(1).tsv',sep='\\t', index_col=[0]) "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7lc6fbOfw16"
      },
      "source": [
        "# **Removing punctuation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "M8iZIjCMfS9r",
        "outputId": "6a31bd3c-381c-4c47-c8bb-b8019ce478eb"
      },
      "source": [
        "import string\n",
        "def remove_punctuations(txt):\n",
        "    text_nopunc=\"\".join([c for c in txt if c not in string.punctuation])\n",
        "    return text_nopunc\n",
        "\n",
        "train['Text']=train['Text'].apply(lambda x: remove_punctuations(x))\n",
        "train"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TA_HL100</th>\n",
              "      <td>Iyaooo Kovam pattutene sothula visatha vachuru...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_HL101</th>\n",
              "      <td>Asha Apo neenga atha government ku theriya pad...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_HL102</th>\n",
              "      <td>Bala sundar ayyo sorryantha line ah explain pa...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_HL105</th>\n",
              "      <td>kalimuthu ne ena lusayaaru edhu panaalum en da...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_HL109</th>\n",
              "      <td>1st baby ku neat ah feed panunga plzz ipdi iru...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_TW6620</th>\n",
              "      <td>Yaroda body structure semaya irukum Sema mood ...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_TW3336</th>\n",
              "      <td>Yenda naangala politics varom nu pala varusham...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_HL1105</th>\n",
              "      <td>Yepdithan seruppala adichalum arasiyalvathikku...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_TW1915</th>\n",
              "      <td>USER Paithiyam ena unga vanthu full ah forward...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_TW4528</th>\n",
              "      <td>RT USER  Itha vidaa kevalam veraa irukaa vijay...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Text Category\n",
              "TA_HL100   Iyaooo Kovam pattutene sothula visatha vachuru...      NOT\n",
              "TA_HL101   Asha Apo neenga atha government ku theriya pad...      NOT\n",
              "TA_HL102   Bala sundar ayyo sorryantha line ah explain pa...      NOT\n",
              "TA_HL105   kalimuthu ne ena lusayaaru edhu panaalum en da...      NOT\n",
              "TA_HL109   1st baby ku neat ah feed panunga plzz ipdi iru...      NOT\n",
              "...                                                      ...      ...\n",
              "TA_TW6620  Yaroda body structure semaya irukum Sema mood ...      OFF\n",
              "TA_TW3336  Yenda naangala politics varom nu pala varusham...      OFF\n",
              "TA_HL1105  Yepdithan seruppala adichalum arasiyalvathikku...      OFF\n",
              "TA_TW1915  USER Paithiyam ena unga vanthu full ah forward...      OFF\n",
              "TA_TW4528  RT USER  Itha vidaa kevalam veraa irukaa vijay...      OFF\n",
              "\n",
              "[4000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91j5V_0sf3vs"
      },
      "source": [
        "# **Spliting to Dev Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rlp7aL2fSzv"
      },
      "source": [
        "X_train, X_dev, y_train, y_dev = train_test_split(train['Text'], train['Category'], test_size=0.30, random_state=42)\n",
        "\n",
        "X_test= test['Text']\n",
        "y_test= test['Category']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMN4auxRwBca"
      },
      "source": [
        "# **Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxRps_FtfSwz"
      },
      "source": [
        "Encoder = LabelEncoder()\n",
        "y_train = Encoder.fit_transform(y_train)\n",
        "y_test = Encoder.transform(y_test)\n",
        "y_dev = Encoder.transform(y_dev)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbfDL9FMiMSj"
      },
      "source": [
        "# **Long Short Term Memory(LSTM)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wTykTpIfStM"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "\n",
        "#use onehot in train\n",
        "voc_size = 1000\n",
        "\n",
        "train_onehot = [one_hot(words, voc_size)for words in X_train]\n",
        "dev_onehot = [one_hot(words, voc_size)for words in X_dev]\n",
        "test_onehot = [one_hot(words, voc_size)for words in X_test]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y-qxoRIfSqA"
      },
      "source": [
        "#performing pad_sequences\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sent_length=100\n",
        "X_train=pad_sequences(train_onehot,padding='pre',maxlen=sent_length)\n",
        "X_dev=pad_sequences(dev_onehot,padding='pre',maxlen=sent_length)\n",
        "X_test = pad_sequences(test_onehot,padding='pre',maxlen=sent_length)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqDK7UZmi0Du",
        "outputId": "4623960e-998a-47ca-d5b2-4a5bf27a3914"
      },
      "source": [
        "dim=40\n",
        "model=Sequential()\n",
        "\n",
        "#embedding layer\n",
        "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
        "\n",
        "#input layer\n",
        "model.add(LSTM(1000, input_shape=(1000,1), return_sequences=False))\n",
        "\n",
        "#hidded layer\n",
        "model.add(Dense(500, activation='relu', kernel_regularizer=regularizers.l2(0.01) ))\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model.compile('adam','mse')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp6E1oUOkAdj",
        "outputId": "28fbec37-15d5-4168-ed0f-972cb8aa0635"
      },
      "source": [
        "#summary of LSTM model\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 40)           40000     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 1000)              4164000   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 2505      \n",
            "=================================================================\n",
            "Total params: 4,707,005\n",
            "Trainable params: 4,707,005\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf2IrBnGkAZV",
        "outputId": "a714c8e8-7b53-47ab-f19d-3ec8c1eb8b17"
      },
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size=64,\n",
        "                    epochs=10, validation_data=(X_dev, y_dev)                 \n",
        "                    )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "44/44 [==============================] - 232s 5s/step - loss: 0.3220 - accuracy: 0.8918 - val_loss: 0.8440 - val_accuracy: 0.6904\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 229s 5s/step - loss: 0.2839 - accuracy: 0.9032 - val_loss: 0.8593 - val_accuracy: 0.6809\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 232s 5s/step - loss: 0.2620 - accuracy: 0.9075 - val_loss: 0.9152 - val_accuracy: 0.6915\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 232s 5s/step - loss: 0.2452 - accuracy: 0.9189 - val_loss: 0.9258 - val_accuracy: 0.6787\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 231s 5s/step - loss: 0.1997 - accuracy: 0.9336 - val_loss: 1.0235 - val_accuracy: 0.6883\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 229s 5s/step - loss: 0.1612 - accuracy: 0.9525 - val_loss: 0.9695 - val_accuracy: 0.6723\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 232s 5s/step - loss: 0.1364 - accuracy: 0.9689 - val_loss: 1.0886 - val_accuracy: 0.6872\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 230s 5s/step - loss: 0.1164 - accuracy: 0.9725 - val_loss: 1.1178 - val_accuracy: 0.6819\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 230s 5s/step - loss: 0.1004 - accuracy: 0.9779 - val_loss: 1.2798 - val_accuracy: 0.6809\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 233s 5s/step - loss: 0.0954 - accuracy: 0.9775 - val_loss: 1.3124 - val_accuracy: 0.6798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvA2qvy7kTNK"
      },
      "source": [
        "#classified with test set\n",
        "y_pred_test_LSTM = model.predict(X_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOgTg7cF9rmp"
      },
      "source": [
        "# **Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abuz7CFk9peD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cdf60c1-555c-4d1e-e19f-9a1123bcefd9"
      },
      "source": [
        "#Simple Neural network\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising\n",
        "NN = Sequential()\n",
        "\n",
        "# Adding input layer and the first hidden layer\n",
        "NN.add(Dense(units = len(train.Category.value_counts()), kernel_initializer = 'uniform', activation = 'relu', input_dim = sent_length))\n",
        "\n",
        "# Adding second hidden layer\n",
        "NN.add(Dense(units = len(train.Category.value_counts()), kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding output layer\n",
        "NN.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "\n",
        "# Compiling the ANN\n",
        "NN.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "NN.fit(X_train, y_train, batch_size =50 , epochs = 10)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = NN.predict(X_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "56/56 [==============================] - 1s 1ms/step - loss: 0.6955 - accuracy: 0.4853\n",
            "Epoch 2/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4892\n",
            "Epoch 3/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5025\n",
            "Epoch 4/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4937\n",
            "Epoch 5/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4977\n",
            "Epoch 6/10\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5095\n",
            "Epoch 7/10\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5108\n",
            "Epoch 8/10\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5051\n",
            "Epoch 9/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4965\n",
            "Epoch 10/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5070\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
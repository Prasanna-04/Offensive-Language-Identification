{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM and NN for OLI .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdbxAM5VEc8-"
      },
      "source": [
        "**Importing Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QTmKTgSeeuQ"
      },
      "source": [
        "#importing required libaries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re \n",
        "import string\n",
        "\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "\n",
        "#keras\n",
        "from keras import *\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.optimizers import  Adam\n",
        "from keras import regularizers"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkpCVt-IEhxb"
      },
      "source": [
        "**Malayalam Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsvufK8Ylh05"
      },
      "source": [
        "#reading the Malayalam dataset\n",
        "train=pd.read_csv('/content/drive/MyDrive/offensive language/Malayalam dataset/Mal_Training_data.tsv',sep='\\t', index_col=[0])\n",
        "test=pd.read_csv('/content/drive/MyDrive/offensive language/Malayalam dataset/mal_test_data_with_labels.tsv',sep='\\t', index_col=[0])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7lc6fbOfw16"
      },
      "source": [
        "# **Removing punctuation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "M8iZIjCMfS9r",
        "outputId": "d9f539d7-3267-4f01-c72f-ebd2e8cbaa17"
      },
      "source": [
        "import string\n",
        "def remove_punctuations(txt):\n",
        "    text_nopunc=\"\".join([c for c in txt if c not in string.punctuation])\n",
        "    return text_nopunc\n",
        "\n",
        "train['Text']=train['Text'].apply(lambda x: remove_punctuations(x))\n",
        "train"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MA_YT001</th>\n",
              "      <td>Thaankal enthaan cheyyarullathðŸ˜›</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT002</th>\n",
              "      <td>Ee theetam WCC feminichigalude news aarkk vena...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT003</th>\n",
              "      <td>fukru nem tiktok oolakale vilich charcha nadat...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT004</th>\n",
              "      <td>Aashiq abu produce cheytharunnel ee problems u...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT005</th>\n",
              "      <td>Pennungal oru team aayal ath moonjum ennu epoo...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT3996</th>\n",
              "      <td>Eee parasayam thanne thettanu Ella achanmaraya...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT3997</th>\n",
              "      <td>Ente bagathum thetundh ee vazhikke veraan paad...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT3998</th>\n",
              "      <td>Kuttiye njan kettikolaam swarnam onnum venda e...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT3999</th>\n",
              "      <td>Chumma veettil irunna chakkiye trollanmaarkku ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT4000</th>\n",
              "      <td>Kalidasan nalla look aayallo kanan Ã°Å¸ËœÂ¬</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Text Category\n",
              "MA_YT001                     Thaankal enthaan cheyyarullathðŸ˜›      NOT\n",
              "MA_YT002   Ee theetam WCC feminichigalude news aarkk vena...      OFF\n",
              "MA_YT003   fukru nem tiktok oolakale vilich charcha nadat...      OFF\n",
              "MA_YT004   Aashiq abu produce cheytharunnel ee problems u...      NOT\n",
              "MA_YT005   Pennungal oru team aayal ath moonjum ennu epoo...      OFF\n",
              "...                                                      ...      ...\n",
              "MA_YT3996  Eee parasayam thanne thettanu Ella achanmaraya...      NOT\n",
              "MA_YT3997  Ente bagathum thetundh ee vazhikke veraan paad...      NOT\n",
              "MA_YT3998  Kuttiye njan kettikolaam swarnam onnum venda e...      NOT\n",
              "MA_YT3999  Chumma veettil irunna chakkiye trollanmaarkku ...      NOT\n",
              "MA_YT4000            Kalidasan nalla look aayallo kanan Ã°Å¸ËœÂ¬      NOT\n",
              "\n",
              "[4000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91j5V_0sf3vs"
      },
      "source": [
        "# **Spliting to Dev Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rlp7aL2fSzv"
      },
      "source": [
        "X_train, X_dev, y_train, y_dev = train_test_split(train['Text'], train['Category'], test_size=0.30, random_state=42)\n",
        "\n",
        "X_test= test['Text']\n",
        "y_test= test['Category']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMN4auxRwBca"
      },
      "source": [
        "# **Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxRps_FtfSwz"
      },
      "source": [
        "Encoder = LabelEncoder()\n",
        "y_train = Encoder.fit_transform(y_train)\n",
        "y_test = Encoder.transform(y_test)\n",
        "y_dev = Encoder.transform(y_dev)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbfDL9FMiMSj"
      },
      "source": [
        "# **Long Short Term Memory(LSTM)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wTykTpIfStM"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "\n",
        "#use onehot in train\n",
        "voc_size = 1000\n",
        "\n",
        "train_onehot = [one_hot(words, voc_size)for words in X_train]\n",
        "dev_onehot = [one_hot(words, voc_size)for words in X_dev]\n",
        "test_onehot = [one_hot(words, voc_size)for words in X_test]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y-qxoRIfSqA"
      },
      "source": [
        "#performing pad_sequences\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sent_length=100\n",
        "X_train=pad_sequences(train_onehot,padding='pre',maxlen=sent_length)\n",
        "X_dev=pad_sequences(dev_onehot,padding='pre',maxlen=sent_length)\n",
        "X_test = pad_sequences(test_onehot,padding='pre',maxlen=sent_length)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqDK7UZmi0Du",
        "outputId": "4ca3d1c7-8a2f-49ac-b540-2c5f955cd2b8"
      },
      "source": [
        "dim=40\n",
        "model=Sequential()\n",
        "\n",
        "#embedding layer\n",
        "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
        "\n",
        "#input layer\n",
        "model.add(LSTM(1000, input_shape=(1000,1), return_sequences=False))\n",
        "\n",
        "#hidded layer\n",
        "model.add(Dense(500, activation='relu', kernel_regularizer=regularizers.l2(0.01) ))\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model.compile('adam','mse')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp6E1oUOkAdj",
        "outputId": "ed5552f4-7c59-4956-9e0d-069a7219348e"
      },
      "source": [
        "#summary of LSTM model\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 100, 40)           40000     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 1000)              4164000   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 5)                 2505      \n",
            "=================================================================\n",
            "Total params: 4,707,005\n",
            "Trainable params: 4,707,005\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf2IrBnGkAZV",
        "outputId": "9d58e340-7753-4aa9-9684-626636d5cccf"
      },
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size=64,\n",
        "                    epochs=10, validation_data=(X_dev, y_dev)                 \n",
        "                    )"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "44/44 [==============================] - 247s 6s/step - loss: 5.9763 - accuracy: 0.4700 - val_loss: 2.7309 - val_accuracy: 0.5075\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 249s 6s/step - loss: 2.3856 - accuracy: 0.4988 - val_loss: 1.6594 - val_accuracy: 0.4925\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 248s 6s/step - loss: 1.5124 - accuracy: 0.5372 - val_loss: 1.2230 - val_accuracy: 0.4975\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 247s 6s/step - loss: 1.0989 - accuracy: 0.6250 - val_loss: 1.0679 - val_accuracy: 0.5033\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 249s 6s/step - loss: 0.8246 - accuracy: 0.7114 - val_loss: 1.0587 - val_accuracy: 0.5308\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 249s 6s/step - loss: 0.6834 - accuracy: 0.7330 - val_loss: 0.9886 - val_accuracy: 0.5150\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 246s 6s/step - loss: 0.6194 - accuracy: 0.7230 - val_loss: 1.0153 - val_accuracy: 0.5242\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 246s 6s/step - loss: 0.6022 - accuracy: 0.6992 - val_loss: 1.0444 - val_accuracy: 0.5200\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 247s 6s/step - loss: 0.5618 - accuracy: 0.7173 - val_loss: 1.0469 - val_accuracy: 0.5192\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 250s 6s/step - loss: 0.5284 - accuracy: 0.7388 - val_loss: 1.0823 - val_accuracy: 0.5208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvA2qvy7kTNK"
      },
      "source": [
        "#classified with test set\n",
        "y_pred_test_LSTM = model.predict(X_test)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOgTg7cF9rmp"
      },
      "source": [
        "# **Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abuz7CFk9peD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd56e96-806f-45db-94fd-bd05b420ffdc"
      },
      "source": [
        "#Simple Neural network\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising\n",
        "NN = Sequential()\n",
        "\n",
        "# Adding input layer and the first hidden layer\n",
        "NN.add(Dense(units = len(train.Category.value_counts()), kernel_initializer = 'uniform', activation = 'relu', input_dim = sent_length))\n",
        "\n",
        "# Adding second hidden layer\n",
        "NN.add(Dense(units = len(train.Category.value_counts()), kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding output layer\n",
        "NN.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "\n",
        "# Compiling the ANN\n",
        "NN.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "NN.fit(X_train, y_train, batch_size =50 , epochs = 10)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = NN.predict(X_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "56/56 [==============================] - 1s 1ms/step - loss: 0.6937 - accuracy: 0.4888\n",
            "Epoch 2/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5271\n",
            "Epoch 3/10\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5253\n",
            "Epoch 4/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5308\n",
            "Epoch 5/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5353\n",
            "Epoch 6/10\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5226\n",
            "Epoch 7/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5290\n",
            "Epoch 8/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5352\n",
            "Epoch 9/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5247\n",
            "Epoch 10/10\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5298\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}